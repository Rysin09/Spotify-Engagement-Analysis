<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/1/19/Spotify_logo_without_text.svg" width="180" />
</p>

<h1 align="center">Spotify Engagement Analysis ğŸ§ğŸ“Š</h1>

<p align="center">
A complete Data Engineering + Analytics pipeline built using <b>AWS S3, Glue, Athena, and Power BI</b>.
</p>

---

## ğŸš€ Project Overview

This project builds an **end-to-end cloud analytics pipeline** that ingests Spotify listening history, transforms it using AWS Glue (PySpark), optimizes storage using Parquet, queries data using Athena, and visualizes insights using Power BI.

You learn & demonstrate **real industry-level data engineering**.

---

## ğŸ—ï¸ Architecture (Concise Flow)
<pre style="background:#f8f8f8; padding:18px; border-radius:6px;">
S3 (Raw CSV)
â†“
Glue Crawler (Auto Schema Detection)
â†“
Glue Data Catalog (RAW Table)
â†“
Glue ETL Job (Transform â†’ Parquet)
â†“
S3 (Processed Parquet)
â†“
Glue Data Catalog (Processed Table)
â†“
Amazon Athena (Query Engine)
â†“
Power BI (Visualization)
  </pre>


---

## ğŸ”§ Tech Stack

| Tool / Service | Purpose |
|----------------|---------|
| **Amazon S3** | Data Lake (Raw + Processed zones) |
| **AWS Glue Crawler** | Detect schema from CSV and build metadata |
| **AWS Glue ETL (PySpark)** | Transform â†’ clean â†’ convert to Parquet |
| **AWS Glue Data Catalog** | Central metadata store for Athena |
| **Amazon Athena** | Serverless SQL engine querying S3 parquet |
| **Power BI** | Dashboards & visual analytics |
| **Python / PySpark** | ETL logic |

---

## ğŸ“ Repository Structure
<pre style="background:#f8f8f8; padding:18px; border-radius:6px;">
  /
â”œâ”€â”€ architecture/
â”‚ â””â”€â”€ aws_spotify_architecture.png
â”‚
â”œâ”€â”€ assets/
â”‚ â”œâ”€â”€ s3_raw.png
â”‚ â”œâ”€â”€ s3_processed.png
â”‚ â”œâ”€â”€ glue_crawler.png
â”‚ â”œâ”€â”€ glue_job_success.png
â”‚ â”œâ”€â”€ athena_query.png
â”‚ â””â”€â”€ powerbi_dashboard.png
â”‚
â”œâ”€â”€ code/
â”‚ â””â”€â”€ glue_etl_script.py
â”‚
â”œâ”€â”€ sql/
â”‚ â””â”€â”€ athena_queries.sql
â”‚
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ project_flow.md
â”‚ â””â”€â”€ powerbi_connection_guide.md
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ sample_spotify_history.csv
â”‚
â””â”€â”€ README.md
</pre>


---

## ğŸ§  What This Pipeline Does

- Converts raw Spotify history into clean, analysis-ready data  
- Generates optimized **Parquet** + **partitioned** data  
- Enables fast SQL analytics through Athena  
- Creates an automated, scalable **data lake â†’ warehouse â†’ BI** workflow  
- Produces a Power BI dashboard with listening insights  

---

## ğŸ“Š Insights Generated

- Total listening time (daily / monthly / yearly)  
- Top artists, top tracks  
- Listening trends over time  
- Skip rate, shuffle behavior  
- Time-of-day analytics  
- Heatmaps for weekday Ã— hour patterns  

---

## ğŸ› ï¸ How It Works (Short Explanation)

**1. Upload Raw CSV â†’ S3**  
Your Spotify history file is added to the data lake (raw zone).

**2. Glue Crawler â†’ Detect Schema**  
Automatically identifies CSV columns & types.  
Creates a RAW table inside Glue Data Catalog.

**3. Glue ETL Job â†’ Transform**  
PySpark script:  
- Cleans timestamps  
- Adds useful columns (year, month, hour, weekday, etc.)  
- Converts CSV â†’ Parquet  
- Writes to S3 processed zone

**4. Athena â†’ Query Layer**  
Athena reads processed Parquet files via the catalog.  
Provides SQL analytics.

**5. Power BI â†’ Dashboard**  
Power BI connects to Athena via ODBC.  
Data is imported and visualized.

---

## ğŸ–¼ï¸ Architecture Diagram

*(Add your AWS dark-theme diagram here)*


